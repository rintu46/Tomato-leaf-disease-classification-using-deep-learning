{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uy-wBrJZtW5i"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.5.2-cp39-cp39-win_amd64.whl (7.2 MB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\envs\\jp\\lib\\site-packages (from matplotlib) (1.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\envs\\jp\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.34.4-py3-none-any.whl (944 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp39-cp39-win_amd64.whl (55 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\anaconda3\\envs\\jp\\lib\\site-packages (from matplotlib) (9.0.0)\n",
      "Collecting pyparsing>=2.2.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting packaging>=20.0\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\jp\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pyparsing, packaging, kiwisolver, fonttools, cycler, matplotlib\n",
      "Successfully installed cycler-0.11.0 fonttools-4.34.4 kiwisolver-1.4.4 matplotlib-3.5.2 packaging-21.3 pyparsing-3.0.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UKgy0P0MtW25"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1304/1408506528.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sV99Iuf5tW0q"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 256\n",
    "CHANNELS=3\n",
    "EPOCHS=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "K7eBkOOLtWyB"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/content/drive/MyDrive/Colab Notebooks/tomato classification'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1304/4023282973.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m dataset = tf.keras.preprocessing.image_dataset_from_directory(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"/content/drive/MyDrive/Colab Notebooks/tomato classification\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m123\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mimage_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jp\\lib\\site-packages\\keras\\preprocessing\\image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m   image_paths, labels, class_names = dataset_utils.index_directory(\n\u001b[0m\u001b[0;32m    191\u001b[0m       \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m       \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jp\\lib\\site-packages\\keras\\preprocessing\\dataset_utils.py\u001b[0m in \u001b[0;36mindex_directory\u001b[1;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0msubdirs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0msubdirs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/content/drive/MyDrive/Colab Notebooks/tomato classification'"
     ]
    }
   ],
   "source": [
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"/content/drive/MyDrive/Colab Notebooks/tomato classification\",\n",
    "    seed=123,\n",
    "    shuffle=True,\n",
    "    image_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mhHFBuymtWvd"
   },
   "outputs": [],
   "source": [
    "class_names = dataset.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPu7iP0otWs_"
   },
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in dataset.take(1):\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jM2wOLkZtWqT"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for image_batch, labels_batch in dataset.take(1):\n",
    "    for i in range(12):\n",
    "        ax = plt.subplot(3, 4, i + 1)\n",
    "        plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels_batch[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQLAmzBptWnr"
   },
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ZjoxZQztWlC"
   },
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "len(dataset)*train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "whUsC_8ztWic"
   },
   "outputs": [],
   "source": [
    "train_ds = dataset.take(54)\n",
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14TACbVttWfj"
   },
   "outputs": [],
   "source": [
    "test_ds = dataset.skip(54)\n",
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8FyiYzxBuDaq"
   },
   "outputs": [],
   "source": [
    "val_size=0.1\n",
    "len(dataset)*val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BJ8BDKb9uDXp"
   },
   "outputs": [],
   "source": [
    "val_ds = test_ds.take(6)\n",
    "len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UNYb173uDU2"
   },
   "outputs": [],
   "source": [
    "test_ds = test_ds.skip(6)\n",
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "va_FYOtDuDRu"
   },
   "outputs": [],
   "source": [
    "def get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
    "    assert (train_split + test_split + val_split) == 1\n",
    "    \n",
    "    ds_size = len(ds)\n",
    "    \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle_size, seed=12)\n",
    "    \n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "    \n",
    "    train_ds = ds.take(train_size)    \n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3d1XS2XuDOz"
   },
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ql8UuMFUuDLz"
   },
   "outputs": [],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e292GbzHuDI9"
   },
   "outputs": [],
   "source": [
    "len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zAcLjhluN54"
   },
   "outputs": [],
   "source": [
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WkcGEL_uQol"
   },
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZXgLX_4uQl3"
   },
   "outputs": [],
   "source": [
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1d9RBPZuQjL"
   },
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OdaynEB6uU_Q"
   },
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(\n",
    "    lambda x, y: (data_augmentation(x, training=True), y)\n",
    ").prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8V2gx3w6uU8j"
   },
   "outputs": [],
   "source": [
    "input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "n_classes = 3\n",
    "\n",
    "tomato_model = models.Sequential([\n",
    "    resize_and_rescale,\n",
    "    layers.Conv2D(32, kernel_size = (3,3), activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(n_classes, activation='softmax'),\n",
    "])\n",
    "\n",
    "tomato_model.build(input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VCvzEAhNuU5t"
   },
   "outputs": [],
   "source": [
    "tomato_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fp0dWN1uU3L"
   },
   "outputs": [],
   "source": [
    "tomato_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H__83NfMuU0k"
   },
   "outputs": [],
   "source": [
    "history = tomato_model.fit(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=val_ds,\n",
    "    verbose=1,\n",
    "    epochs=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eW8BNMwiufG8"
   },
   "outputs": [],
   "source": [
    "scores = tomato_model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9EG5gnEufEi"
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5Ug_aSRufCC"
   },
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jWTl3v7Nue_g"
   },
   "outputs": [],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rcFJSmimue9A"
   },
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_dDjA0lue6c"
   },
   "outputs": [],
   "source": [
    "type(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U7ssG-cZue32"
   },
   "outputs": [],
   "source": [
    "len(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9M3ImciHue1J"
   },
   "outputs": [],
   "source": [
    "history.history['loss'][:5] # show loss for first 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "azOmC9xDueyi"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvtOMWazuevw"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(EPOCHS), acc, label='Training Accuracy')\n",
    "plt.plot(range(EPOCHS), val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(EPOCHS), loss, label='Training Loss')\n",
    "plt.plot(range(EPOCHS), val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0RH7hZGUues9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for images_batch, labels_batch in test_ds.take(1):\n",
    "    \n",
    "    first_image = images_batch[0].numpy().astype('uint8')\n",
    "    first_label = labels_batch[0].numpy()\n",
    "    \n",
    "    print(\"first image to predict\")\n",
    "    plt.imshow(first_image)\n",
    "    print(\"actual label:\",class_names[first_label])\n",
    "    \n",
    "    batch_prediction = tomato_model.predict(images_batch)\n",
    "    print(\"predicted label:\",class_names[np.argmax(batch_prediction[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KuaQFVK9uuVD"
   },
   "outputs": [],
   "source": [
    "def predict(model, img):\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    predicted_class = class_names[np.argmax(predictions[0])]\n",
    "    confidence = round(100 * (np.max(predictions[0])), 2)\n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WDnnVkTRuuSf"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "for images, labels in test_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        \n",
    "        predicted_class, confidence = predict(tomato_model, images[i].numpy())\n",
    "        actual_class = class_names[labels[i]] \n",
    "        \n",
    "        plt.title(f\"Actual: {actual_class},\\n Predicted: {predicted_class}.\\n Confidence: {confidence}%\")\n",
    "        \n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hyrrBMFAuuPv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9rjVKV_uuM8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ckF4XD4Oskv"
   },
   "outputs": [],
   "source": [
    "# dataset2 = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     \"/content/drive/MyDrive/Colab Notebooks/test data\",\n",
    "#     seed=123,\n",
    "#     shuffle=True,\n",
    "#     image_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "#     batch_size=BATCH_SIZE\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XhNEEGm4PAux"
   },
   "outputs": [],
   "source": [
    "# class_names = dataset2.class_names\n",
    "# class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0JzT-OPuOsiA"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 10))\n",
    "# for image_batch, labels_batch in dataset2.take(1):\n",
    "#     for i in range(5):\n",
    "#         ax = plt.subplot(3, 4, i + 1)\n",
    "#         plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "#         plt.title(class_names[labels_batch[i]])\n",
    "#         plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFZiO1J4OsfE"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# for images_batch, labels_batch in dataset2.take(16):\n",
    "    \n",
    "#     first_image = images_batch[0].numpy().astype('uint8')\n",
    "#     first_label = labels_batch[0].numpy()\n",
    "    \n",
    "#     print(\"first image to predict\")\n",
    "#     plt.imshow(first_image)\n",
    "#     print(\"actual label:\",class_names[first_label])\n",
    "    \n",
    "#     batch_prediction = tomato_model.predict(images_batch)\n",
    "#     print(\"predicted label:\",class_names[np.argmax(batch_prediction[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ChSlCkqcOsce"
   },
   "outputs": [],
   "source": [
    "# def predict(model, img):\n",
    "#     img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
    "#     img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "#     predictions = model.predict(img_array)\n",
    "\n",
    "#     predicted_class = class_names[np.argmax(predictions[0])]\n",
    "#     confidence = round(100 * (np.max(predictions[0])), 2)\n",
    "#     return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jDz6oWqkOsZl"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 15))\n",
    "# for images, labels in dataset2.take(1):\n",
    "#     for i in range(3):\n",
    "#         ax = plt.subplot(3, 3, i + 1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        \n",
    "#         predicted_class, confidence = predict(tomato_model, images[i].numpy())\n",
    "#         actual_class = class_names[labels[i]] \n",
    "        \n",
    "#         plt.title(f\"Actual: {actual_class},\\n Predicted: {predicted_class}.\\n Confidence: {confidence}%\")\n",
    "        \n",
    "#         plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DlJorbQ6sHG"
   },
   "source": [
    "making the prediction on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OHyMoa-96r59"
   },
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_mD05g7ULdL"
   },
   "outputs": [],
   "source": [
    "# test_img = r'/content/5.JPG'\n",
    "# img_result = Image.open(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EPqOyuAywfHv"
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# cv2.cvtColor(np.float32(img_result), cv2.COLOR_RGB2GRAY)\n",
    "# # gray = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "# plt.imshow(cv2.cvtColor(np.float32(img_result), cv2.COLOR_RGB2GRAY))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "923JsqB9zCi-"
   },
   "outputs": [],
   "source": [
    "# img2 = cv2.imread('/content/1.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D87bTSGOx3xC"
   },
   "outputs": [],
   "source": [
    "# resize = tf.image.resize(img2,(256,256))\n",
    "# plt.imshow(resize.numpy().astype(int))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6QjkJpaOx3uA"
   },
   "outputs": [],
   "source": [
    "# yt = tomato_model.predict(np.expand_dims(resize/255,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zlsnj-yG2Y3b"
   },
   "outputs": [],
   "source": [
    "# yt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jid2MphD8-D1"
   },
   "outputs": [],
   "source": [
    "# print([np.max(yt[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHjmfSZu7DSS"
   },
   "outputs": [],
   "source": [
    "# predict_class = class_names[np.argmax(yt[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eKAFLQA660os"
   },
   "outputs": [],
   "source": [
    "# print(int(np.max(yt[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iVK7Uz_t6ImC"
   },
   "outputs": [],
   "source": [
    "# index = np.argmax(yt[0])\n",
    "# print(class_names[int(np.max(yt[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_9888-jz6FTi"
   },
   "outputs": [],
   "source": [
    "# print([np.argmax(yt[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FS1T2Pik29dn"
   },
   "outputs": [],
   "source": [
    "# class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9Ugz36_54kS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x2zQ5nxu2sHt"
   },
   "outputs": [],
   "source": [
    "# print(\"predicted label:\",class_names[np.argmax(yt[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yMKXIfp-x3rM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJ_rEGobvOvm"
   },
   "outputs": [],
   "source": [
    "# print(type(img_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GKRI_WlivfCi"
   },
   "outputs": [],
   "source": [
    "# def predict(model, img):\n",
    "#     img_array = tf.keras.preprocessing.image.img_to_array(img_result.numpy())\n",
    "#     img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "#     predictions = model.predict(img_array)\n",
    "\n",
    "#     predicted_class = class_names[np.argmax(predictions[0])]\n",
    "#     confidence = round(100 * (np.max(predictions[0])), 2)\n",
    "#     return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V3h3ykX5v6Jw"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# for images_batch, labels_batch in img_result:\n",
    "    \n",
    "#     first_image = images_batch[0].numpy().astype('uint8')\n",
    "#     first_label = labels_batch[0].numpy()\n",
    "    \n",
    "#     print(\"first image to predict\")\n",
    "#     plt.imshow(first_image)\n",
    "#     print(\"actual label:\",class_names[first_label])\n",
    "    \n",
    "#     batch_prediction = model.predict(images_batch)\n",
    "#     print(\"predicted label:\",class_names[np.argmax(batch_prediction[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "paoILjygtqwf"
   },
   "outputs": [],
   "source": [
    "# Image.open(test_img).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7U8lZKdPuD8R"
   },
   "outputs": [],
   "source": [
    "#  first_image = img_result.numpy().astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igx7mllStZl3"
   },
   "outputs": [],
   "source": [
    " \n",
    "# first_image = images_batch.numpy().astype('uint8')\n",
    "# first_label = labels_batch.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5ihdDpUULaf"
   },
   "outputs": [],
   "source": [
    "# def predict(model, img):\n",
    "#     img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
    "#     img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "#     predictions = tomato_model.predict(img_array)\n",
    "\n",
    "#     predicted_class = class_names[np.argmax(predictions[0])]\n",
    "#     confidence = round(100 * (np.max(predictions[0])), 2)\n",
    "#     return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BGp_2NkFULX-"
   },
   "outputs": [],
   "source": [
    "# predicted_class, confidence = predict(tomato_model, img_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVwoVtmHU_O_"
   },
   "outputs": [],
   "source": [
    "# plt.imshow(img_result)\n",
    "# plt.title(f\"Predicted: {predicted_class}.\\n Confidence: {confidence}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nqr-zhvtU_MC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjs246bUU_Jb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80s1Zq7g6r3b"
   },
   "outputs": [],
   "source": [
    "# test_img = r'/content/3.JPG'\n",
    "# img_result = Image.open(test_img)\n",
    "\n",
    "\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# test_img = image.load_img(test_img,target_size=(224,224))\n",
    "# test_img = image.img_to_array(test_img)\n",
    "# test_img = test_img/255\n",
    "# test_img = np.expand_dims(test_img,axis=0)\n",
    "\n",
    "# result=model.predict(test_img)\n",
    "# print(np.argmax(result))\n",
    "\n",
    "# categories = ['Tomato_Early_blight', 'Tomato_Late_blight', 'Tomato_healthy']\n",
    "# # categories = [np.argmax(result)]\n",
    "\n",
    "\n",
    "# img_result = plt.imshow(img_result)\n",
    "# plt.title(categories[np.argmax(result)])\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "njZ8sV6FERDS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imzMf-JN6r0q"
   },
   "outputs": [],
   "source": [
    "# test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2p4ota4Hl5p"
   },
   "outputs": [],
   "source": [
    "# from io import BytesIO\n",
    "# from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQchAsBM6rx5"
   },
   "outputs": [],
   "source": [
    "# img3 = r'/content/5.JPG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqkaM4nIHazU"
   },
   "outputs": [],
   "source": [
    "# g = np.array(Image.open(BytesIO(img3)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "tomato leaf disease classification.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python [conda env:jp]",
   "language": "python",
   "name": "conda-env-jp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
