{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uy-wBrJZtW5i"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.util.dispatch' has no attribute 'add_fallback_dispatch_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models, layers\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTML\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\colab\\lib\\site-packages\\keras\\api\\_v2\\keras\\__init__.py:12\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_v2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_v2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\colab\\lib\\site-packages\\keras\\__init__.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\colab\\lib\\site-packages\\keras\\models\\__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\colab\\lib\\site-packages\\keras\\engine\\functional.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layout_map \u001b[38;5;28;01mas\u001b[39;00m layout_map_lib\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer_utils\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\colab\\lib\\site-packages\\keras\\dtensor\\__init__.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Conditional import the dtensor API, since it is currently broken in OSS.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _DTENSOR_API_ENABLED:\n\u001b[1;32m---> 22\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtensor \u001b[38;5;28;01mas\u001b[39;00m dtensor_api  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m   \u001b[38;5;66;03m# Leave it with a placeholder, so that the import line from other python file\u001b[39;00m\n\u001b[0;32m     25\u001b[0m   \u001b[38;5;66;03m# will not break.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m   dtensor_api \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\colab\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v2\\experimental\\dtensor\\__init__.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf.experimental.dtensor namespace.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m call_with_layout\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_layout\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m client_id\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\colab\\lib\\site-packages\\tensorflow\\dtensor\\python\\__init__.py:17\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"DTensor Python API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_dtensor_ops \u001b[38;5;28;01mas\u001b[39;00m ops\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mesh_util\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tpu_util\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\colab\\lib\\site-packages\\tensorflow\\dtensor\\python\\gen_dtensor_ops.py:23\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TypeVar\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;129m@_dispatch\u001b[39m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_fallback_dispatch_list\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@_dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_type_based_api_dispatcher\n\u001b[0;32m     25\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfigure_and_initialize_global_tpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfigure_and_initialize_global_tpu\u001b[39m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     27\u001b[0m   \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"An op that sets up the centralized structures for a distributed TPU\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m  system.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m    A vector containing the global TPU id of each TPU on the host.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m     38\u001b[0m   _ctx \u001b[38;5;241m=\u001b[39m _context\u001b[38;5;241m.\u001b[39m_context \u001b[38;5;129;01mor\u001b[39;00m _context\u001b[38;5;241m.\u001b[39mcontext()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.python.util.dispatch' has no attribute 'add_fallback_dispatch_list'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UKgy0P0MtW25"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sV99Iuf5tW0q"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 256\n",
    "CHANNELS=3\n",
    "EPOCHS=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7eBkOOLtWyB"
   },
   "outputs": [],
   "source": [
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"/content/drive/MyDrive/Colab Notebooks/tomato classification\",\n",
    "    seed=123,\n",
    "    shuffle=True,\n",
    "    image_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mhHFBuymtWvd"
   },
   "outputs": [],
   "source": [
    "class_names = dataset.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPu7iP0otWs_"
   },
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in dataset.take(1):\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jM2wOLkZtWqT"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for image_batch, labels_batch in dataset.take(1):\n",
    "    for i in range(12):\n",
    "        ax = plt.subplot(3, 4, i + 1)\n",
    "        plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels_batch[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQLAmzBptWnr"
   },
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ZjoxZQztWlC"
   },
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "len(dataset)*train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "whUsC_8ztWic"
   },
   "outputs": [],
   "source": [
    "train_ds = dataset.take(54)\n",
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14TACbVttWfj"
   },
   "outputs": [],
   "source": [
    "test_ds = dataset.skip(54)\n",
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8FyiYzxBuDaq"
   },
   "outputs": [],
   "source": [
    "val_size=0.1\n",
    "len(dataset)*val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BJ8BDKb9uDXp"
   },
   "outputs": [],
   "source": [
    "val_ds = test_ds.take(6)\n",
    "len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UNYb173uDU2"
   },
   "outputs": [],
   "source": [
    "test_ds = test_ds.skip(6)\n",
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "va_FYOtDuDRu"
   },
   "outputs": [],
   "source": [
    "def get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
    "    assert (train_split + test_split + val_split) == 1\n",
    "    \n",
    "    ds_size = len(ds)\n",
    "    \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle_size, seed=12)\n",
    "    \n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "    \n",
    "    train_ds = ds.take(train_size)    \n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3d1XS2XuDOz"
   },
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ql8UuMFUuDLz"
   },
   "outputs": [],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e292GbzHuDI9"
   },
   "outputs": [],
   "source": [
    "len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zAcLjhluN54"
   },
   "outputs": [],
   "source": [
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WkcGEL_uQol"
   },
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZXgLX_4uQl3"
   },
   "outputs": [],
   "source": [
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1d9RBPZuQjL"
   },
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OdaynEB6uU_Q"
   },
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(\n",
    "    lambda x, y: (data_augmentation(x, training=True), y)\n",
    ").prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8V2gx3w6uU8j"
   },
   "outputs": [],
   "source": [
    "input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "n_classes = 3\n",
    "\n",
    "tomato_model = models.Sequential([\n",
    "    resize_and_rescale,\n",
    "    layers.Conv2D(32, kernel_size = (3,3), activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(n_classes, activation='softmax'),\n",
    "])\n",
    "\n",
    "tomato_model.build(input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VCvzEAhNuU5t"
   },
   "outputs": [],
   "source": [
    "tomato_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fp0dWN1uU3L"
   },
   "outputs": [],
   "source": [
    "tomato_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H__83NfMuU0k"
   },
   "outputs": [],
   "source": [
    "history = tomato_model.fit(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=val_ds,\n",
    "    verbose=1,\n",
    "    epochs=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eW8BNMwiufG8"
   },
   "outputs": [],
   "source": [
    "scores = tomato_model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9EG5gnEufEi"
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5Ug_aSRufCC"
   },
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jWTl3v7Nue_g"
   },
   "outputs": [],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rcFJSmimue9A"
   },
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_dDjA0lue6c"
   },
   "outputs": [],
   "source": [
    "type(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U7ssG-cZue32"
   },
   "outputs": [],
   "source": [
    "len(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9M3ImciHue1J"
   },
   "outputs": [],
   "source": [
    "history.history['loss'][:5] # show loss for first 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "azOmC9xDueyi"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvtOMWazuevw"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(EPOCHS), acc, label='Training Accuracy')\n",
    "plt.plot(range(EPOCHS), val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(EPOCHS), loss, label='Training Loss')\n",
    "plt.plot(range(EPOCHS), val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0RH7hZGUues9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for images_batch, labels_batch in test_ds.take(1):\n",
    "    \n",
    "    first_image = images_batch[0].numpy().astype('uint8')\n",
    "    first_label = labels_batch[0].numpy()\n",
    "    \n",
    "    print(\"first image to predict\")\n",
    "    plt.imshow(first_image)\n",
    "    print(\"actual label:\",class_names[first_label])\n",
    "    \n",
    "    batch_prediction = tomato_model.predict(images_batch)\n",
    "    print(\"predicted label:\",class_names[np.argmax(batch_prediction[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KuaQFVK9uuVD"
   },
   "outputs": [],
   "source": [
    "def predict(model, img):\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    predicted_class = class_names[np.argmax(predictions[0])]\n",
    "    confidence = round(100 * (np.max(predictions[0])), 2)\n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WDnnVkTRuuSf"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "for images, labels in test_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        \n",
    "        predicted_class, confidence = predict(tomato_model, images[i].numpy())\n",
    "        actual_class = class_names[labels[i]] \n",
    "        \n",
    "        plt.title(f\"Actual: {actual_class},\\n Predicted: {predicted_class}.\\n Confidence: {confidence}%\")\n",
    "        \n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hyrrBMFAuuPv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9rjVKV_uuM8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ckF4XD4Oskv"
   },
   "outputs": [],
   "source": [
    "# dataset2 = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     \"/content/drive/MyDrive/Colab Notebooks/test data\",\n",
    "#     seed=123,\n",
    "#     shuffle=True,\n",
    "#     image_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "#     batch_size=BATCH_SIZE\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XhNEEGm4PAux"
   },
   "outputs": [],
   "source": [
    "# class_names = dataset2.class_names\n",
    "# class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0JzT-OPuOsiA"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 10))\n",
    "# for image_batch, labels_batch in dataset2.take(1):\n",
    "#     for i in range(5):\n",
    "#         ax = plt.subplot(3, 4, i + 1)\n",
    "#         plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "#         plt.title(class_names[labels_batch[i]])\n",
    "#         plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFZiO1J4OsfE"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# for images_batch, labels_batch in dataset2.take(16):\n",
    "    \n",
    "#     first_image = images_batch[0].numpy().astype('uint8')\n",
    "#     first_label = labels_batch[0].numpy()\n",
    "    \n",
    "#     print(\"first image to predict\")\n",
    "#     plt.imshow(first_image)\n",
    "#     print(\"actual label:\",class_names[first_label])\n",
    "    \n",
    "#     batch_prediction = tomato_model.predict(images_batch)\n",
    "#     print(\"predicted label:\",class_names[np.argmax(batch_prediction[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ChSlCkqcOsce"
   },
   "outputs": [],
   "source": [
    "# def predict(model, img):\n",
    "#     img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
    "#     img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "#     predictions = model.predict(img_array)\n",
    "\n",
    "#     predicted_class = class_names[np.argmax(predictions[0])]\n",
    "#     confidence = round(100 * (np.max(predictions[0])), 2)\n",
    "#     return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jDz6oWqkOsZl"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 15))\n",
    "# for images, labels in dataset2.take(1):\n",
    "#     for i in range(3):\n",
    "#         ax = plt.subplot(3, 3, i + 1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        \n",
    "#         predicted_class, confidence = predict(tomato_model, images[i].numpy())\n",
    "#         actual_class = class_names[labels[i]] \n",
    "        \n",
    "#         plt.title(f\"Actual: {actual_class},\\n Predicted: {predicted_class}.\\n Confidence: {confidence}%\")\n",
    "        \n",
    "#         plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DlJorbQ6sHG"
   },
   "source": [
    "making the prediction on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OHyMoa-96r59"
   },
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_mD05g7ULdL"
   },
   "outputs": [],
   "source": [
    "# test_img = r'/content/5.JPG'\n",
    "# img_result = Image.open(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EPqOyuAywfHv"
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# cv2.cvtColor(np.float32(img_result), cv2.COLOR_RGB2GRAY)\n",
    "# # gray = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "# plt.imshow(cv2.cvtColor(np.float32(img_result), cv2.COLOR_RGB2GRAY))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "923JsqB9zCi-"
   },
   "outputs": [],
   "source": [
    "# img2 = cv2.imread('/content/1.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D87bTSGOx3xC"
   },
   "outputs": [],
   "source": [
    "# resize = tf.image.resize(img2,(256,256))\n",
    "# plt.imshow(resize.numpy().astype(int))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6QjkJpaOx3uA"
   },
   "outputs": [],
   "source": [
    "# yt = tomato_model.predict(np.expand_dims(resize/255,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zlsnj-yG2Y3b"
   },
   "outputs": [],
   "source": [
    "# yt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jid2MphD8-D1"
   },
   "outputs": [],
   "source": [
    "# print([np.max(yt[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHjmfSZu7DSS"
   },
   "outputs": [],
   "source": [
    "# predict_class = class_names[np.argmax(yt[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eKAFLQA660os"
   },
   "outputs": [],
   "source": [
    "# print(int(np.max(yt[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iVK7Uz_t6ImC"
   },
   "outputs": [],
   "source": [
    "# index = np.argmax(yt[0])\n",
    "# print(class_names[int(np.max(yt[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_9888-jz6FTi"
   },
   "outputs": [],
   "source": [
    "# print([np.argmax(yt[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FS1T2Pik29dn"
   },
   "outputs": [],
   "source": [
    "# class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9Ugz36_54kS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x2zQ5nxu2sHt"
   },
   "outputs": [],
   "source": [
    "# print(\"predicted label:\",class_names[np.argmax(yt[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yMKXIfp-x3rM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJ_rEGobvOvm"
   },
   "outputs": [],
   "source": [
    "# print(type(img_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GKRI_WlivfCi"
   },
   "outputs": [],
   "source": [
    "# def predict(model, img):\n",
    "#     img_array = tf.keras.preprocessing.image.img_to_array(img_result.numpy())\n",
    "#     img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "#     predictions = model.predict(img_array)\n",
    "\n",
    "#     predicted_class = class_names[np.argmax(predictions[0])]\n",
    "#     confidence = round(100 * (np.max(predictions[0])), 2)\n",
    "#     return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V3h3ykX5v6Jw"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# for images_batch, labels_batch in img_result:\n",
    "    \n",
    "#     first_image = images_batch[0].numpy().astype('uint8')\n",
    "#     first_label = labels_batch[0].numpy()\n",
    "    \n",
    "#     print(\"first image to predict\")\n",
    "#     plt.imshow(first_image)\n",
    "#     print(\"actual label:\",class_names[first_label])\n",
    "    \n",
    "#     batch_prediction = model.predict(images_batch)\n",
    "#     print(\"predicted label:\",class_names[np.argmax(batch_prediction[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "paoILjygtqwf"
   },
   "outputs": [],
   "source": [
    "# Image.open(test_img).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7U8lZKdPuD8R"
   },
   "outputs": [],
   "source": [
    "#  first_image = img_result.numpy().astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igx7mllStZl3"
   },
   "outputs": [],
   "source": [
    " \n",
    "# first_image = images_batch.numpy().astype('uint8')\n",
    "# first_label = labels_batch.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5ihdDpUULaf"
   },
   "outputs": [],
   "source": [
    "# def predict(model, img):\n",
    "#     img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
    "#     img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "#     predictions = tomato_model.predict(img_array)\n",
    "\n",
    "#     predicted_class = class_names[np.argmax(predictions[0])]\n",
    "#     confidence = round(100 * (np.max(predictions[0])), 2)\n",
    "#     return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BGp_2NkFULX-"
   },
   "outputs": [],
   "source": [
    "# predicted_class, confidence = predict(tomato_model, img_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVwoVtmHU_O_"
   },
   "outputs": [],
   "source": [
    "# plt.imshow(img_result)\n",
    "# plt.title(f\"Predicted: {predicted_class}.\\n Confidence: {confidence}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nqr-zhvtU_MC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjs246bUU_Jb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80s1Zq7g6r3b"
   },
   "outputs": [],
   "source": [
    "# test_img = r'/content/3.JPG'\n",
    "# img_result = Image.open(test_img)\n",
    "\n",
    "\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# test_img = image.load_img(test_img,target_size=(224,224))\n",
    "# test_img = image.img_to_array(test_img)\n",
    "# test_img = test_img/255\n",
    "# test_img = np.expand_dims(test_img,axis=0)\n",
    "\n",
    "# result=model.predict(test_img)\n",
    "# print(np.argmax(result))\n",
    "\n",
    "# categories = ['Tomato_Early_blight', 'Tomato_Late_blight', 'Tomato_healthy']\n",
    "# # categories = [np.argmax(result)]\n",
    "\n",
    "\n",
    "# img_result = plt.imshow(img_result)\n",
    "# plt.title(categories[np.argmax(result)])\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "njZ8sV6FERDS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imzMf-JN6r0q"
   },
   "outputs": [],
   "source": [
    "# test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2p4ota4Hl5p"
   },
   "outputs": [],
   "source": [
    "# from io import BytesIO\n",
    "# from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQchAsBM6rx5"
   },
   "outputs": [],
   "source": [
    "# img3 = r'/content/5.JPG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqkaM4nIHazU"
   },
   "outputs": [],
   "source": [
    "# g = np.array(Image.open(BytesIO(img3)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "tomato leaf disease classification.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python [conda env:colab]",
   "language": "python",
   "name": "conda-env-colab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
